package com.apollographql.apollo3.compiler

import com.apollographql.apollo3.compiler.frontend.GQLFragmentDefinition
import com.apollographql.apollo3.compiler.frontend.GraphQLParser
import com.apollographql.apollo3.compiler.frontend.Schema
import com.apollographql.apollo3.compiler.frontend.toUtf8
import com.squareup.moshi.JsonClass
import java.io.File

/**
 * metadata generated by a previous run of [GraphQLCompiler]. The schema and fragments are stored as GraphQL document strings. This
 * slightly unfortunate because that means we will parse them twice but there isn't many alternatives as validation and IR-building takes
 * GQLDocuments as inputs. We could add our own intermediate binary format but it's not guaranteed to be any faster.
 *
 * This also means that we need to ensure the types references will stay valid so we enforce that schemaPackageName is always the same.
 */
data class ApolloMetadata(
    /**
     * Might be null if the schema is coming from upstream
     */
    val schema: Schema?,
    /**
     * The fragments
     */
    val fragments: List<GQLFragmentDefinition>,
    /**
     * The generated input objects, enums
     */
    val generatedEnums: Set<String>,
    val generatedInputObjects: Set<String>,
    val schemaPackageName: String?,
    val rootPackageName: String?,
    /**
     * The module name, for debug
     */
    val moduleName: String,
    val generateKotlinModels: Boolean,
    val pluginVersion: String,
    val customScalarsMapping: Map<String, String>
) {
  @JsonClass(generateAdapter = true)
  internal class JsonMetadata(
      val schema: String?,
      val fragments: String,
      val generatedInputObjects: Set<String>,
      val generatedEnums: Set<String>,
      val schemaPackageName: String?,
      val rootPackageName: String?,
      val moduleName: String,
      val generateKotlinModels: Boolean,
      val pluginVersion: String,
      val customScalarsMapping: Map<String, String>
  )

  companion object {
    fun List<ApolloMetadata>.merge(): ApolloMetadata? {
      if (isEmpty()) {
        return null
      }
      // ensure a single schema
      val rootMetadataList = filter { it.schema != null }
      check(rootMetadataList.size <= 1) {
        "Apollo: A schema is defined in multiple modules: ${rootMetadataList.map { it.moduleName }.joinToString(", ")}.\n" +
            "There should be only one root module defining the schema, check your dependencies."
      }
      check(rootMetadataList.isNotEmpty()) {
        "Apollo: Cannot find a schema in parent modules. Searched in ${map { it.moduleName }.joinToString(", ")}"
      }
      val rootMetadata = rootMetadataList.first()

      // ensure the same schemaPackageName
      map { it.schemaPackageName }.filterNotNull().distinct().let {
        check(it.size == 1) {
          "Apollo: All modules should have the same schemaPackageName. Found:" + it.joinToString(", ")
        }
      }

      // ensure the same generateKotlinModels
      map { it.generateKotlinModels }.distinct().let {
        check(it.size == 1) {
          "Apollo: All modules should have the same generateKotlinModels. Found:" + it.joinToString(", ")
        }
      }

      // ensure the same pluginVersion
      map { it.pluginVersion }.distinct().let {
        check(it.size == 1) {
          "Apollo: All modules should be generated with the same apollo version. Found:" + it.joinToString(", ")
        }
      }

      // no need to validate distinct fragment names, this will be done later when aggregating the Fragments
      return rootMetadata.copy(
          fragments = flatMap { it.fragments },
          moduleName = "*",
          generatedEnums = flatMap { it.generatedEnums }.toSet(),
          generatedInputObjects = flatMap { it.generatedInputObjects }.toSet(),
      )
    }

    fun readFrom(file: File): ApolloMetadata {
      val serializedMetadata = file.fromJson<JsonMetadata>()
      return with(serializedMetadata) {
        ApolloMetadata(
            schema = schema?.let { GraphQLParser.parseSchema(it) },
            fragments = GraphQLParser.parseDocument(fragments).orThrow().definitions.map { it as GQLFragmentDefinition },
            generatedEnums = generatedEnums,
            generatedInputObjects = generatedInputObjects,
            schemaPackageName = schemaPackageName,
            rootPackageName = rootPackageName,
            moduleName = moduleName,
            generateKotlinModels = generateKotlinModels,
            pluginVersion = pluginVersion,
            customScalarsMapping = customScalarsMapping
        )
      }
    }
  }

  fun writeTo(file: File) {
    val serializedMetadata = JsonMetadata(
        schema = schema?.toDocument()?.toUtf8(),
        fragments = fragments.map { it.toUtf8() }.joinToString("\n"),
        generatedEnums = generatedEnums,
        generatedInputObjects = generatedInputObjects,
        schemaPackageName = schemaPackageName,
        rootPackageName = rootPackageName,
        moduleName = moduleName,
        generateKotlinModels = generateKotlinModels,
        pluginVersion = pluginVersion,
        customScalarsMapping = customScalarsMapping
    )
    serializedMetadata.toJson(file)
  }

}
